{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, add, Activation, MaxPooling2D, Conv2D, Dropout, Flatten\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "path_aircraft = r\"Ct_Scan_Dataset\\\\covidct\"\n",
    "path_car = r\"Ct_Scan_Dataset\\\\normalct\"\n",
    "path_cat = r\"Ct_Scan_Dataset\\\\Penomoni\"\n",
    "path_dog = r\"Ct_Scan_Dataset\\\\Boronsit\"\n",
    "path_flower = r\"Ct_Scan_Dataset\\\\Possible Covid\"\n",
    "path_fruit = r\"Ct_Scan_Dataset\\\\possible Penomoni\"\n",
    "\n",
    "\n",
    "aircraft = os.listdir(path_aircraft)\n",
    "car = os.listdir(path_car)\n",
    "cat = os.listdir(path_cat)\n",
    "dog = os.listdir(path_dog)\n",
    "flower = os.listdir(path_flower)\n",
    "fruit = os.listdir(path_fruit)\n",
    "\n",
    "\n",
    "aircraft_img_path = aircraft\n",
    "car_img_path = car\n",
    "cat_img_path = cat\n",
    "dog_img_path = dog\n",
    "flower_img_path = flower\n",
    "fruit_img_path = fruit\n",
    "\n",
    "\n",
    "len_aircraft = len(aircraft)\n",
    "len_car = len(car)\n",
    "len_cat = len(cat)\n",
    "len_dog = len(dog)\n",
    "len_flower = len(flower)\n",
    "len_fruit = len(fruit)\n",
    "\n",
    "\n",
    "for i in range(0,len_aircraft):\n",
    "    aircraft_img_path[i] = os.path.abspath(os.path.join(path_aircraft,aircraft[i]))\n",
    "for i in range(0,len_car):\n",
    "    car_img_path[i] = os.path.abspath(os.path.join(path_car,car[i]))\n",
    "for i in range(0,len_cat):\n",
    "    cat_img_path[i] = os.path.abspath(os.path.join(path_cat,cat[i]))\n",
    "for i in range(0,len_dog):\n",
    "    dog_img_path[i] = os.path.abspath(os.path.join(path_dog,dog[i]))\n",
    "for i in range(0,len_flower):\n",
    "    flower_img_path[i] = os.path.abspath(os.path.join(path_flower,flower[i]))\n",
    "for i in range(0,len_fruit):\n",
    "    fruit_img_path[i] = os.path.abspath(os.path.join(path_fruit,fruit[i]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_aircraft = np.zeros([727,64,64,3])\n",
    "for i in range(0,len_aircraft):\n",
    "    aa = mpimg.imread(aircraft_img_path[i])\n",
    "    img_aircraft[i] = np.resize(aa,(64,64,3))\n",
    "    \n",
    "img_car = np.zeros([968,64,64,3])\n",
    "for i in range(0,len_car):\n",
    "    bb = mpimg.imread(car_img_path[i])\n",
    "    img_car[i] = np.resize(bb,(64,64,3))\n",
    "\n",
    "img_cat = np.zeros([885,64,64,3])\n",
    "for i in range(0,len_cat):\n",
    "    cc = mpimg.imread(cat_img_path[i])\n",
    "    img_cat[i] = np.resize(cc,(64,64,3))\n",
    "    \n",
    "img_dog = np.zeros([702,64,64,3])\n",
    "for i in range(0,len_dog):\n",
    "    dd = mpimg.imread(dog_img_path[i])\n",
    "    img_dog[i] = np.resize(dd,(64,64,3))\n",
    "    \n",
    "img_flower = np.zeros([843,64,64,3])\n",
    "for i in range(0,len_flower):\n",
    "    ee = mpimg.imread(flower_img_path[i])\n",
    "    img_flower[i] = np.resize(ee,(64,64,3))\n",
    "    \n",
    "img_fruit = np.zeros([1000,64,64,3])\n",
    "for i in range(0,len_fruit):\n",
    "    ff = mpimg.imread(fruit_img_path[i])\n",
    "    img_fruit[i] = np.resize(ff,(64,64,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate((img_aircraft, img_car), axis=0)\n",
    "X = np.concatenate((X, img_cat), axis=0)\n",
    "X = np.concatenate((X, img_dog), axis=0)\n",
    "X = np.concatenate((X, img_flower), axis=0)\n",
    "X = np.concatenate((X, img_fruit), axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = np.chararray((727,1), itemsize=8)\n",
    "y1[:] = 'covidct'\n",
    "y2 = np.chararray((968,1), itemsize=3)\n",
    "y2[:] = 'normalct'\n",
    "y3 = np.chararray((885,1), itemsize=3)\n",
    "y3[:] = 'Penomoni'\n",
    "y4 = np.chararray((702,1), itemsize=3)\n",
    "y4[:] = 'Boronsit'\n",
    "y5 = np.chararray((843,1), itemsize=6)\n",
    "y5[:] = 'Possible Covid'\n",
    "y6 = np.chararray((1000,1), itemsize=5)\n",
    "y6[:] = 'possible Penomoni'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.concatenate((y1, y2), axis=0)\n",
    "y = np.concatenate((y, y3), axis=0)\n",
    "y = np.concatenate((y, y4), axis=0)\n",
    "y = np.concatenate((y, y5), axis=0)\n",
    "y = np.concatenate((y, y6), axis=0)\n",
    "#y = np.concatenate((y, y7), axis=0)\n",
    "#y = np.concatenate((y, y8), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:251: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit_transform(y)\n",
    "y_encoded = encoder.transform(y)\n",
    "\n",
    "y_dummy = np_utils.to_categorical(y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_dummy, test_size=0.23, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3,3), input_shape=(64,64,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(16, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(6, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3946/3946 [==============================] - 40s 10ms/step - loss: 0.5110 - acc: 0.8214\n",
      "Epoch 2/10\n",
      "3946/3946 [==============================] - 33s 8ms/step - loss: 0.4841 - acc: 0.8324\n",
      "Epoch 3/10\n",
      "3946/3946 [==============================] - 35s 9ms/step - loss: 0.4674 - acc: 0.8330\n",
      "Epoch 4/10\n",
      "3946/3946 [==============================] - 34s 9ms/step - loss: 0.4608 - acc: 0.8333\n",
      "Epoch 5/10\n",
      "3946/3946 [==============================] - 35s 9ms/step - loss: 0.4562 - acc: 0.8333\n",
      "Epoch 6/10\n",
      "3946/3946 [==============================] - 35s 9ms/step - loss: 0.4546 - acc: 0.8334\n",
      "Epoch 7/10\n",
      "3946/3946 [==============================] - 36s 9ms/step - loss: 0.4547 - acc: 0.8334\n",
      "Epoch 8/10\n",
      "3946/3946 [==============================] - 37s 9ms/step - loss: 0.4534 - acc: 0.8334\n",
      "Epoch 9/10\n",
      "3946/3946 [==============================] - 34s 9ms/step - loss: 0.4538 - acc: 0.8334\n",
      "Epoch 10/10\n",
      "3946/3946 [==============================] - 35s 9ms/step - loss: 0.4532 - acc: 0.8334\n"
     ]
    }
   ],
   "source": [
    "H1 = model.fit(X_train, y_train, epochs=10, batch_size=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 29, 29, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               802944    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 6)                 102       \n",
      "=================================================================\n",
      "Total params: 822,486\n",
      "Trainable params: 822,486\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'acc'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(H1.history.keys())\n",
    "\n",
    "plt.plot(H1.history[\"loss\"])\n",
    "plt.plot(H1.history[\"acc\"])\n",
    "plt.legend(['loss', 'accuracy'], loc='upper left')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss & accuracy maeasure\")\n",
    "plt.title(\"Distribution of Accuracy and Loss over the epochs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1179/1179 [==============================] - 3s 2ms/step\n",
      "The score loss of test model is 0.449376\n",
      "The score accuracy of test model is 83.333331\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(\"The score loss of test model is %f\" %(score[0]))\n",
    "print(\"The score accuracy of test model is %f\" %(score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1179/1179 [==============================] - 2s 2ms/step\n",
      "The accuracy of the predicted model using the deep learning multi class classification is 99.721446%\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test,  batch_size=100, verbose=1)\n",
    "print(\"The accuracy of the predicted model using the deep learning multi class classification is %f\" %(100-np.mean(np.abs(y_pred - y_test)))+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.13980243, 0.17555225, 0.16482499, 0.14041427, 0.19734168,\n",
       "        0.19777805], dtype=float32),\n",
       " array([0., 0., 1., 0., 0., 0.], dtype=float32))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[3], y_test[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1179, 6)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1179, 6)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1179, 6)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-0a06afa4fae9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# training_set.class_indices\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mimggg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'0.jpg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"This Xray Image is of Negative covid-19 patient\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mimggg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimggg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#from google.colab.patches import cv2_imshow\n",
    "from keras.preprocessing import image\n",
    "xtest_image = image.load_img('0.jpg', target_size = (64, 64))\n",
    "xtest_image = image.img_to_array(xtest_image)\n",
    "xtest_image = np.expand_dims(xtest_image, axis = 0)\n",
    "results = model.predict_classes(xtest_image)\n",
    "# training_set.class_indices\n",
    "\n",
    "imggg = cv2.imread('0.jpg')\n",
    "print(\"This Xray Image is of Negative covid-19 patient\")\n",
    "imggg = np.array(imggg)\n",
    "imggg = cv2.resize(imggg,(400,400))\n",
    "\n",
    "plt.imshow(imggg)\n",
    "# cv2_imshow(imggg)\n",
    "# print(results)\n",
    "#if results[0][0] == 0:\n",
    "#    prediction = 'Positive For Covid-19'\n",
    "#else:\n",
    "#    prediction = 'Negative for Covid-19'\n",
    "    \n",
    "    \n",
    "#print(\"Prediction Of Our Model : \",prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32,(3,3),activation = \"relu\",input_shape=(224,224,3)))\n",
    "model.add(Conv2D(64,(3,3),activation = \"relu\"))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(64,(3,3),activation = 'relu'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(128,(3,3),activation ='relu'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64,activation = \"relu\"))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(6,activation = 'sigmoid'))\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy',optimizer = \"adam\",metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 222, 222, 32)      896       \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 220, 220, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 110, 110, 64)      0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 110, 110, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 108, 108, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 54, 54, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 54, 54, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 52, 52, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 26, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 26, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 86528)             0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 64)                5537856   \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 5,668,422\n",
      "Trainable params: 5,668,422\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = image.ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.2,\n",
    "    horizontal_flip = True,\n",
    ")\n",
    "\n",
    "val_gen = image.ImageDataGenerator(\n",
    "    rescale = 1./255\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 291 images belonging to 6 classes.\n",
      "Found 353 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_gen.flow_from_directory(\n",
    "    \"DataSet\\seg_train\",\n",
    "    target_size = (224,224),\n",
    "    batch_size = 32,\n",
    "    class_mode = \"categorical\",\n",
    ")\n",
    "val_generator = val_gen.flow_from_directory(\n",
    "    \"DataSet\\seg_test\",\n",
    "    target_size = (224,224),\n",
    "    batch_size = 32,\n",
    "    class_mode = \"categorical\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Boronsit': 0,\n",
       " 'Penomoni': 1,\n",
       " 'Possible Covid': 2,\n",
       " 'covidct': 3,\n",
       " 'normalct': 4,\n",
       " 'possible Penomoni': 5}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint,EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "9/9 [==============================] - 185s 21s/step - loss: 0.9693 - acc: 0.7448 - val_loss: 0.5097 - val_acc: 0.8333\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 137s 15s/step - loss: 0.5068 - acc: 0.8269 - val_loss: 0.5085 - val_acc: 0.8333\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 130s 14s/step - loss: 0.4891 - acc: 0.8263 - val_loss: 0.5027 - val_acc: 0.8333\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 129s 14s/step - loss: 0.4817 - acc: 0.8175 - val_loss: 0.4891 - val_acc: 0.8333\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 131s 15s/step - loss: 0.4888 - acc: 0.8169 - val_loss: 0.5127 - val_acc: 0.8333\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 125s 14s/step - loss: 0.4856 - acc: 0.8234 - val_loss: 0.4930 - val_acc: 0.8333\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 130s 14s/step - loss: 0.4807 - acc: 0.8246 - val_loss: 0.4877 - val_acc: 0.8333\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 131s 15s/step - loss: 0.4667 - acc: 0.8254 - val_loss: 0.4736 - val_acc: 0.8333\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 130s 14s/step - loss: 0.4765 - acc: 0.8316 - val_loss: 0.4728 - val_acc: 0.8333\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 131s 15s/step - loss: 0.4764 - acc: 0.8281 - val_loss: 0.5004 - val_acc: 0.8333\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=9,\n",
    "    epochs=10,\n",
    "    validation_data = val_generator,\n",
    "    validation_steps = 2,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(114, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "val_path = \"Ct_Scan_Dataset\"\n",
    "test_imgs = []\n",
    "\n",
    "for img_ in os.listdir(val_path+\"/covidct\"):\n",
    "    img_path = os.path.join(val_path+\"/covidct\",img_)\n",
    "    img = image.load_img(img_path,target_size = (224,224))\n",
    "    img = image.img_to_array(img)/255.0\n",
    "    test_imgs.append(img)\n",
    "    \n",
    "for img_ in os.listdir(val_path+\"/normalct\"):\n",
    "    img_path = os.path.join(val_path+\"/normalct\",img_)\n",
    "    img = image.load_img(img_path,target_size = (224,224))\n",
    "    img = image.img_to_array(img)/255.0\n",
    "    test_imgs.append(img)\n",
    "\n",
    "    \n",
    "for img_ in os.listdir(val_path+\"/normalct\"):\n",
    "    img_path = os.path.join(val_path+\"/normalct\",img_)\n",
    "    img = image.load_img(img_path,target_size = (224,224))\n",
    "    img = image.img_to_array(img)/255.0\n",
    "    test_imgs.append(img)\n",
    "\n",
    "for img_ in os.listdir(val_path+\"/Boronsit\"):\n",
    "    img_path = os.path.join(val_path+\"/Boronsit\",img_)\n",
    "    img = image.load_img(img_path,target_size = (224,224))\n",
    "    img = image.img_to_array(img)/255.0\n",
    "    test_imgs.append(img)\n",
    "    \n",
    "for img_ in os.listdir(val_path+\"/Penomoni\"):\n",
    "    img_path = os.path.join(val_path+\"/Penomoni\",img_)\n",
    "    img = image.load_img(img_path,target_size = (224,224))\n",
    "    img = image.img_to_array(img)/255.0\n",
    "    test_imgs.append(img)\n",
    "for img_ in os.listdir(val_path+\"/Possible Covid\"):\n",
    "    img_path = os.path.join(val_path+\"/Possible Covid\",img_)\n",
    "    img = image.load_img(img_path,target_size = (224,224))\n",
    "    img = image.img_to_array(img)/255.0\n",
    "    test_imgs.append(img)\n",
    "for img_ in os.listdir(val_path+\"/possible Penomoni\"):\n",
    "    img_path = os.path.join(val_path+\"/possible Penomoni\",img_)\n",
    "    img = image.load_img(img_path,target_size = (224,224))\n",
    "    img = image.img_to_array(img)/255.0\n",
    "    test_imgs.append(img)\n",
    "test_imgs = np.array(test_imgs)\n",
    "print(test_imgs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(114,)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# labels of all the images\n",
    "# Boronsit --> 0, Penomoni --> 1, Possible Covid --> 2, covidct --> 3, normalct --> 4, possible Penomoni --> 5    \n",
    "lth = int(test_imgs.shape[0]/2)\n",
    "labels = np.hstack((np.zeros(lth),np.ones(lth)))\n",
    "print(labels.shape)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 5 5 5 5 5 5 5 5 5 5 5 2 2 2 2 5 5 5 5 2 2 2 2 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 2 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 2 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5]\n"
     ]
    }
   ],
   "source": [
    "y_pred = []\n",
    "for i in range(test_imgs.shape[0]):\n",
    "    img = np.expand_dims(test_imgs[i],axis=0)\n",
    "    pred = model.predict_classes(img)\n",
    "    y_pred.append(pred[0])\n",
    "\n",
    "y_pred = np.array(y_pred)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['conv2d_7',\n",
       " 'conv2d_8',\n",
       " 'max_pooling2d_6',\n",
       " 'dropout_8',\n",
       " 'conv2d_9',\n",
       " 'max_pooling2d_7',\n",
       " 'dropout_9',\n",
       " 'conv2d_10',\n",
       " 'max_pooling2d_8',\n",
       " 'dropout_10',\n",
       " 'flatten_3',\n",
       " 'dense_7',\n",
       " 'dropout_11',\n",
       " 'dense_8']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i.name for i in model.layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
